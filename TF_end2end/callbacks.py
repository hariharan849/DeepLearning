# -*- coding: utf-8 -*-
"""tf_callbacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R-HhysEHNcjoFGFuIpChlWIZQ3Y5ZCXX
"""

import os
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, Callback

class Callbacks:

    def __init__(self, output_path):
      self._output_path = output_path

    def get_callbacks(self):
      ckpoint_path = os.path.join(self._output_path, "ck_pt")
      if not os.path.exists(ckpoint_path):
          os.makedirs(ckpoint_path)
      tensorboard_path = os.path.join(self._output_path, "tensorboard")
      if not os.path.exists(tensorboard_path):
          os.makedirs(tensorboard_path)

      fig_path = os.path.sep.join([self._output_path, "output", "{}.png".format(os.getpid())])
      json_path = os.path.sep.join([self._output_path, "json", "{}.json".format(os.getpid())])

      if not os.path.exists(os.path.dirname(fig_path)):
          os.makedirs(os.path.dirname(fig_path))
      json_path = os.path.join(os.path.dirname(image_folder), "json")
      if not os.path.exists(os.path.dirname(json_path)):
          os.makedirs(os.path.dirname(json_path))
      callbacks = [
          Callbacks.reduce_lr_on_plateau(),
          Callbacks.early_stopping(),
          Callbacks.model_checkpoint(ckpoint_path),
          Callbacks.tensorboard(log_dir=tensorboard_path),
          Callbacks.training_monitor(fig_path, json_path)
      ]
      return callbacks

    @staticmethod
    def training_monitor(fig_path: str, json_path: str):
        """ Monitor training at each epoch

        Args:
            fig_path(str): Path to save training plots
            json_path(str): Path to save training results as json
        """
        return TrainingMonitor(fig_path, json_path)

    @staticmethod
    def reduce_lr_on_plateau(metric_to_monitor='val_loss', mode="min", factor=0.2, patience=5, min_lr=0.001, min_delta=0.001):
        """ Callback to reduce learning rate on plateau

            KwArgs:
                metric_to_monitor(str): Quantity to be monitored.
                mode(str): When to stop training in mode(min, max, auto)
                factor(float): Factor by which the learning rate will be reduced. new_lr = lr * factor.
                patience(int): Number of epochs with no improvement after which learning rate will be reduced.
                min_lr(float): Lower bound on the learning rate.
                min_delta(float): Threshold for measuring the new optimum, to only focus on significant changes.
        """
        return ReduceLROnPlateau(
            monitor=metric_to_monitor, factor=factor, patience=patience, min_lr=min_lr,
            min_delta=min_delta, mode=mode, verbose=1
        )

    @staticmethod
    def early_stopping(monitor='val_loss', mode='min', patience=50, restore_best_weights=True):
        """ Stop training when a monitored metric has stopped improving.

            KwArgs:
                monitor(str): Quantity to be monitored.
                mode(str): When to stop training in mode(min, max, auto)
                patience(int): Number of epochs with no improvement after which training will be stopped
                restore_best_weights(bool):
        """
        return EarlyStopping(monitor=monitor, mode=mode, verbose=1, patience=patience, restore_best_weights=restore_best_weights)

    @staticmethod
    def model_checkpoint(dirname, monitor="val_loss", mode="min", save_best_only=True):
        """ save only the *best* model to disk based on the validation loss

            Args:
                dirname(str): Name of the directory to save model
            KwArgs:
                monitor(str): Quantity to be monitored
                mode(str): When to stop training in mode(min, max, auto)
                save_best_only(bool): restore model weights from the epoch with the best value of the monitored quantity
        """
        fname = os.path.join(dirname, "weights-{epoch:03d}-{val_loss:.4f}.keras")
        return ModelCheckpoint(fname, monitor="val_loss", mode="min", save_best_only=True, verbose=1)

    @staticmethod
    def tensorboard(log_dir="./logs", profile_batch=5):
        """ Enable visualizations for TensorBoard.
            KwArgs:
                log_dir(str): path of the directory to save the log files
                profile_batch(int): Profile the batch
        """
        return TensorBoard(log_dir=log_dir, profile_batch=profile_batch)